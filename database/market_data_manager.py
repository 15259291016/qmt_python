#!/usr/bin/env python3
"""
å¸‚åœºæ•°æ®ç®¡ç†å™¨
ä¸“é—¨ç”¨äºè®°å½•å¸‚åœºæ•°æ®ï¼Œä¸ºé‡åŒ–AIæ¨¡å‹å‡†å¤‡

ä½œè€…: AI Assistant
åˆ›å»ºæ—¶é—´: 2025-01-15
ç‰ˆæœ¬: 1.0
"""

import os
import sys
import logging
import pymysql
import pandas as pd
from typing import Dict, Any, List, Optional, Union, Tuple
from contextlib import contextmanager
from datetime import datetime, date
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class MarketDataManager:
    """å¸‚åœºæ•°æ®ç®¡ç†å™¨ - ä¸“æ³¨äºæ•°æ®å­˜å‚¨"""
    
    def __init__(self, 
                 host: str = 'localhost',
                 port: int = 3306,
                 user: str = 'market_data_app',
                 password: str = 'app_password',
                 database: str = 'market_data',
                 charset: str = 'utf8mb4',
                 autocommit: bool = False):
        """
        åˆå§‹åŒ–å¸‚åœºæ•°æ®ç®¡ç†å™¨
        
        Args:
            host: æ•°æ®åº“ä¸»æœº
            port: æ•°æ®åº“ç«¯å£
            user: æ•°æ®åº“ç”¨æˆ·å
            password: æ•°æ®åº“å¯†ç 
            database: æ•°æ®åº“åç§°
            charset: å­—ç¬¦é›†
            autocommit: æ˜¯å¦è‡ªåŠ¨æäº¤
        """
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.database = database
        self.charset = charset
        self.autocommit = autocommit
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('MarketDataManager')
        logger.setLevel(logging.INFO)
        
        # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # è®¾ç½®æ ¼å¼
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(formatter)
        
        logger.addHandler(console_handler)
        
        return logger
    
    def get_connection(self) -> pymysql.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        try:
            connection = pymysql.connect(
                host=self.host,
                port=self.port,
                user=self.user,
                password=self.password,
                database=self.database,
                charset=self.charset,
                autocommit=self.autocommit,
                cursorclass=pymysql.cursors.DictCursor
            )
            self.logger.debug(f"åˆ›å»ºæ•°æ®åº“è¿æ¥: {self.host}:{self.port}/{self.database}")
            return connection
        except Exception as e:
            self.logger.error(f"åˆ›å»ºæ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    @contextmanager
    def get_cursor(self):
        """è·å–æ•°æ®åº“æ¸¸æ ‡çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        connection = None
        cursor = None
        try:
            connection = self.get_connection()
            cursor = connection.cursor()
            yield cursor
        except Exception as e:
            if connection:
                connection.rollback()
            self.logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            raise
        finally:
            if cursor:
                cursor.close()
            if connection:
                connection.close()
    
    def execute_query(self, sql: str, params: Optional[Tuple] = None) -> List[Dict]:
        """æ‰§è¡ŒæŸ¥è¯¢SQL"""
        with self.get_cursor() as cursor:
            cursor.execute(sql, params)
            return cursor.fetchall()
    
    def execute_update(self, sql: str, params: Optional[Tuple] = None) -> int:
        """æ‰§è¡Œæ›´æ–°SQL"""
        with self.get_cursor() as cursor:
            result = cursor.execute(sql, params)
            cursor.connection.commit()
            return result
    
    def execute_batch(self, sql: str, params_list: List[Tuple]) -> int:
        """æ‰¹é‡æ‰§è¡ŒSQL"""
        with self.get_cursor() as cursor:
            result = cursor.executemany(sql, params_list)
            cursor.connection.commit()
            return result
    
    def insert_dataframe(self, df: pd.DataFrame, table_name: str, 
                        if_exists: str = 'append', index: bool = False) -> int:
        """å°†DataFrameæ’å…¥æ•°æ®åº“"""
        try:
            with self.get_cursor() as cursor:
                connection = cursor.connection
                df.to_sql(table_name, connection, if_exists=if_exists, index=index, method='multi')
                return len(df)
        except Exception as e:
            self.logger.error(f"æ’å…¥DataFrameå¤±è´¥: {e}")
            raise
    
    def query_dataframe(self, sql: str, params: Optional[Tuple] = None) -> pd.DataFrame:
        """æŸ¥è¯¢æ•°æ®å¹¶è¿”å›DataFrame"""
        try:
            with self.get_cursor() as cursor:
                df = pd.read_sql(sql, cursor.connection, params=params)
                return df
        except Exception as e:
            self.logger.error(f"æŸ¥è¯¢DataFrameå¤±è´¥: {e}")
            raise
    
    # ========================================
    # è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ç›¸å…³æ–¹æ³•
    # ========================================
    
    def get_stock_list(self, market: Optional[str] = None) -> List[Dict]:
        """è·å–è‚¡ç¥¨åˆ—è¡¨"""
        sql = "SELECT * FROM stock_basic"
        params = None
        
        if market:
            sql += " WHERE market = %s"
            params = (market,)
        
        return self.execute_query(sql, params)
    
    def insert_stock_basic(self, df: pd.DataFrame) -> int:
        """æ’å…¥è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
        return self.insert_dataframe(df, 'stock_basic', if_exists='append')
    
    def get_stock_info(self, symbol: str) -> Optional[Dict]:
        """è·å–è‚¡ç¥¨ä¿¡æ¯"""
        sql = "SELECT * FROM stock_basic WHERE symbol = %s"
        result = self.execute_query(sql, (symbol,))
        return result[0] if result else None
    
    # ========================================
    # å¸‚åœºæ•°æ®ç›¸å…³æ–¹æ³•
    # ========================================
    
    def insert_tick_data(self, df: pd.DataFrame) -> int:
        """æ’å…¥tickæ•°æ®"""
        return self.insert_dataframe(df, 'tick_data', if_exists='append')
    
    def insert_minute_data(self, df: pd.DataFrame) -> int:
        """æ’å…¥åˆ†é’Ÿæ•°æ®"""
        return self.insert_dataframe(df, 'minute_data', if_exists='append')
    
    def insert_daily_data(self, df: pd.DataFrame) -> int:
        """æ’å…¥æ—¥çº¿æ•°æ®"""
        return self.insert_dataframe(df, 'daily_data', if_exists='append')
    
    def insert_adj_factor(self, df: pd.DataFrame) -> int:
        """æ’å…¥å¤æƒå› å­"""
        return self.insert_dataframe(df, 'adj_factor', if_exists='append')
    
    def get_tick_data(self, symbol: str, start_time: str, end_time: str) -> pd.DataFrame:
        """è·å–tickæ•°æ®"""
        sql = """
        SELECT * FROM tick_data 
        WHERE symbol = %s AND tick_time BETWEEN %s AND %s
        ORDER BY tick_time
        """
        return self.query_dataframe(sql, (symbol, start_time, end_time))
    
    def get_minute_data(self, symbol: str, start_time: str, end_time: str) -> pd.DataFrame:
        """è·å–åˆ†é’Ÿæ•°æ®"""
        sql = """
        SELECT * FROM minute_data 
        WHERE symbol = %s AND datetime BETWEEN %s AND %s
        ORDER BY datetime
        """
        return self.query_dataframe(sql, (symbol, start_time, end_time))
    
    def get_daily_data(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """è·å–æ—¥çº¿æ•°æ®"""
        sql = """
        SELECT * FROM daily_data 
        WHERE symbol = %s AND trade_date BETWEEN %s AND %s
        ORDER BY trade_date
        """
        return self.query_dataframe(sql, (symbol, start_date, end_date))
    
    def get_latest_price(self, symbol: str) -> Optional[float]:
        """è·å–æœ€æ–°ä»·æ ¼"""
        sql = """
        SELECT close FROM daily_data 
        WHERE symbol = %s 
        ORDER BY trade_date DESC 
        LIMIT 1
        """
        result = self.execute_query(sql, (symbol,))
        return result[0]['close'] if result else None
    
    def get_latest_tick_data(self, symbol: str, limit: int = 100) -> pd.DataFrame:
        """è·å–æœ€æ–°tickæ•°æ®"""
        sql = """
        SELECT * FROM tick_data 
        WHERE symbol = %s 
        ORDER BY tick_time DESC 
        LIMIT %s
        """
        return self.query_dataframe(sql, (symbol, limit))
    
    # ========================================
    # æŠ€æœ¯æŒ‡æ ‡ç›¸å…³æ–¹æ³•
    # ========================================
    
    def insert_technical_indicators(self, df: pd.DataFrame) -> int:
        """æ’å…¥æŠ€æœ¯æŒ‡æ ‡"""
        return self.insert_dataframe(df, 'technical_indicators', if_exists='append')
    
    def get_technical_indicators(self, symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
        """è·å–æŠ€æœ¯æŒ‡æ ‡"""
        sql = """
        SELECT * FROM technical_indicators 
        WHERE symbol = %s AND trade_date BETWEEN %s AND %s
        ORDER BY trade_date
        """
        return self.query_dataframe(sql, (symbol, start_date, end_date))
    
    def calculate_technical_indicators(self, symbol: str, days: int = 60) -> int:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        sql = "CALL CalculateTechnicalIndicators(%s, %s)"
        return self.execute_update(sql, (symbol, days))
    
    # ========================================
    # æ•°æ®åŒæ­¥ç›¸å…³æ–¹æ³•
    # ========================================
    
    def update_sync_status(self, data_type: str, symbol: str, status: str, 
                          record_count: int = 0, error_message: str = '') -> int:
        """æ›´æ–°åŒæ­¥çŠ¶æ€"""
        sql = """
        INSERT INTO data_sync_status (data_type, symbol, last_sync_time, sync_status, record_count, error_message)
        VALUES (%s, %s, NOW(), %s, %s, %s)
        ON DUPLICATE KEY UPDATE
        last_sync_time = NOW(),
        sync_status = VALUES(sync_status),
        record_count = VALUES(record_count),
        error_message = VALUES(error_message),
        updated_at = NOW()
        """
        return self.execute_update(sql, (data_type, symbol, status, record_count, error_message))
    
    def get_sync_status(self, data_type: Optional[str] = None) -> pd.DataFrame:
        """è·å–åŒæ­¥çŠ¶æ€"""
        sql = "SELECT * FROM data_sync_status"
        params = None
        
        if data_type:
            sql += " WHERE data_type = %s"
            params = (data_type,)
        
        sql += " ORDER BY last_sync_time DESC"
        return self.query_dataframe(sql, params)
    
    # ========================================
    # æ•°æ®ç»Ÿè®¡ç›¸å…³æ–¹æ³•
    # ========================================
    
    def get_data_statistics(self) -> Dict:
        """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        sql = "SELECT * FROM v_data_statistics"
        result = self.execute_query(sql)
        
        stats = {}
        for row in result:
            stats[row['data_type']] = {
                'total_records': row['total_records'],
                'unique_symbols': row['unique_symbols'],
                'earliest_time': row['earliest_time'],
                'latest_time': row['latest_time']
            }
        
        return stats
    
    def get_stock_summary(self) -> pd.DataFrame:
        """è·å–è‚¡ç¥¨æ±‡æ€»ä¿¡æ¯"""
        sql = "SELECT * FROM v_stock_summary ORDER BY latest_date DESC"
        return self.query_dataframe(sql)
    
    def get_data_coverage(self, symbol: str) -> Dict:
        """è·å–æ•°æ®è¦†ç›–æƒ…å†µ"""
        coverage = {}
        
        # tickæ•°æ®è¦†ç›–
        sql = """
        SELECT 
            COUNT(*) as count,
            MIN(tick_time) as start_time,
            MAX(tick_time) as end_time
        FROM tick_data WHERE symbol = %s
        """
        result = self.execute_query(sql, (symbol,))
        coverage['tick_data'] = result[0] if result else {}
        
        # åˆ†é’Ÿæ•°æ®è¦†ç›–
        sql = """
        SELECT 
            COUNT(*) as count,
            MIN(datetime) as start_time,
            MAX(datetime) as end_time
        FROM minute_data WHERE symbol = %s
        """
        result = self.execute_query(sql, (symbol,))
        coverage['minute_data'] = result[0] if result else {}
        
        # æ—¥çº¿æ•°æ®è¦†ç›–
        sql = """
        SELECT 
            COUNT(*) as count,
            MIN(trade_date) as start_time,
            MAX(trade_date) as end_time
        FROM daily_data WHERE symbol = %s
        """
        result = self.execute_query(sql, (symbol,))
        coverage['daily_data'] = result[0] if result else {}
        
        return coverage
    
    # ========================================
    # æ•°æ®æ¸…ç†ç›¸å…³æ–¹æ³•
    # ========================================
    
    def clean_historical_data(self, days_to_keep: int = 30) -> int:
        """æ¸…ç†å†å²æ•°æ®"""
        sql = "CALL CleanHistoricalData(%s)"
        result = self.execute_query(sql, (days_to_keep,))
        return result[0]['deleted_rows'] if result else 0
    
    # ========================================
    # ç³»ç»Ÿé…ç½®ç›¸å…³æ–¹æ³•
    # ========================================
    
    def get_system_config(self, config_key: str) -> Optional[str]:
        """è·å–ç³»ç»Ÿé…ç½®"""
        sql = "SELECT config_value FROM system_config WHERE config_key = %s AND is_active = 1"
        result = self.execute_query(sql, (config_key,))
        return result[0]['config_value'] if result else None
    
    def set_system_config(self, config_key: str, config_value: str, 
                         config_type: str = 'string', description: str = '') -> int:
        """è®¾ç½®ç³»ç»Ÿé…ç½®"""
        sql = """
        INSERT INTO system_config (config_key, config_value, config_type, description)
        VALUES (%s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE
        config_value = VALUES(config_value),
        config_type = VALUES(config_type),
        description = VALUES(description),
        updated_at = NOW()
        """
        return self.execute_update(sql, (config_key, config_value, config_type, description))
    
    # ========================================
    # å·¥å…·æ–¹æ³•
    # ========================================
    
    def test_connection(self) -> bool:
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        try:
            with self.get_cursor() as cursor:
                cursor.execute("SELECT 1")
                result = cursor.fetchone()
                return result is not None
        except Exception as e:
            self.logger.error(f"æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def get_table_info(self, table_name: str) -> Dict:
        """è·å–è¡¨ä¿¡æ¯"""
        sql = """
        SELECT 
            TABLE_NAME,
            TABLE_ROWS,
            ROUND((DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024, 2) as size_mb,
            CREATE_TIME,
            UPDATE_TIME
        FROM information_schema.TABLES 
        WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s
        """
        result = self.execute_query(sql, (self.database, table_name))
        return result[0] if result else {}
    
    def export_data_to_csv(self, symbol: str, data_type: str, start_date: str, end_date: str, 
                          output_dir: str = 'data/export') -> str:
        """å¯¼å‡ºæ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # æ ¹æ®æ•°æ®ç±»å‹è·å–æ•°æ®
            if data_type == 'tick':
                df = self.get_tick_data(symbol, f"{start_date} 00:00:00", f"{end_date} 23:59:59")
                filename = f"{symbol}_{data_type}_{start_date}_{end_date}.csv"
            elif data_type == 'minute':
                df = self.get_minute_data(symbol, f"{start_date} 00:00:00", f"{end_date} 23:59:59")
                filename = f"{symbol}_{data_type}_{start_date}_{end_date}.csv"
            elif data_type == 'daily':
                df = self.get_daily_data(symbol, start_date, end_date)
                filename = f"{symbol}_{data_type}_{start_date}_{end_date}.csv"
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
            
            # ä¿å­˜åˆ°CSV
            filepath = output_path / filename
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            
            self.logger.info(f"æ•°æ®å¯¼å‡ºæˆåŠŸ: {filepath}")
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
            raise


# åˆ›å»ºé»˜è®¤å¸‚åœºæ•°æ®ç®¡ç†å™¨å®ä¾‹
def get_default_market_data_manager() -> MarketDataManager:
    """è·å–é»˜è®¤å¸‚åœºæ•°æ®ç®¡ç†å™¨å®ä¾‹"""
    return MarketDataManager()


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # åˆ›å»ºå¸‚åœºæ•°æ®ç®¡ç†å™¨
    manager = MarketDataManager()
    
    # æµ‹è¯•è¿æ¥
    if manager.test_connection():
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        
        # è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        stats = manager.get_data_statistics()
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡: {stats}")
        
        # è·å–è‚¡ç¥¨æ±‡æ€»ä¿¡æ¯
        summary = manager.get_stock_summary()
        print(f"ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {len(summary)}")
        
        # è·å–è¡¨ä¿¡æ¯
        table_info = manager.get_table_info('daily_data')
        print(f"ğŸ“‹ æ—¥çº¿æ•°æ®è¡¨ä¿¡æ¯: {table_info}")
    else:
        print("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼")

